{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dkt\n",
    "\n",
    "- 원래 정답률이 높았던 스킬에 대해, 연속적으로 맞을수록 오히려 정답확률이 떨어지는 경향을 보임\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset 로드\n",
    "from data_loaders.assist2009 import ASSIST2009\n",
    "\n",
    "dataset = ASSIST2009(100)\n",
    "\n",
    "#model 로드\n",
    "import json\n",
    "\n",
    "with open(\"config.json\") as f:\n",
    "    config = json.load(f)\n",
    "    model_config = config[\"dkt\"]\n",
    "    train_config = config[\"train_config\"]\n",
    "    \n",
    "import torch \n",
    "from models.dkt import DKT\n",
    "\n",
    "model = DKT(dataset.num_q, **model_config)\n",
    "model.load_state_dict(torch.load('./ckpts/dkt/ASSIST2009/model.ckpt'))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "#test_dataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "train_size = int(len(dataset) * 0.9)\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(\n",
    "        dataset, [train_size, test_size], generator=torch.Generator(device='cuda')\n",
    "    )\n",
    "\n",
    "if os.path.exists(os.path.join(dataset.dataset_dir, \"train_indices.pkl\")):\n",
    "    with open(\n",
    "        os.path.join(dataset.dataset_dir, \"train_indices.pkl\"), \"rb\"\n",
    "    ) as f:\n",
    "        train_dataset.indices = pickle.load(f)\n",
    "    with open(\n",
    "        os.path.join(dataset.dataset_dir, \"test_indices.pkl\"), \"rb\"\n",
    "    ) as f:\n",
    "        test_dataset.indices = pickle.load(f)     \n",
    "        \n",
    "from models.utils import collate_fn\n",
    "\n",
    "test_loader = DataLoader(\n",
    "        test_dataset, batch_size=test_size, shuffle=False,\n",
    "        collate_fn=collate_fn, generator=torch.Generator(device='cuda') #0607 hson\n",
    "    )\n",
    "\n",
    "for data in test_loader:\n",
    "    q, r, qshft, rshft, m = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import one_hot, binary_cross_entropy\n",
    "from sklearn import metrics\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "DATASET_DIR = \"datasets/ASSIST2009/\"\n",
    "with open(os.path.join(DATASET_DIR, \"q2idx.pkl\"), \"rb\") as f:\n",
    "    q2idx = pickle.load(f)\n",
    "idx2q = {v:k for k,v in q2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학생의 문제 skill id 시퀀스:  [22.0, 83.0, 100.0, 82.0, 100.0, 100.0, 82.0, 82.0, 20.0] \n",
      "\n",
      "각 문제 정오답 여부 시퀀스:  [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0] \n",
      "\n",
      "output:  tensor([0.2943, 0.3964, 0.4870, 0.5639, 0.6939, 0.4791, 0.5294, 0.7135],\n",
      "       device='cpu') \n",
      "\n",
      "true:  tensor([0., 1., 0., 1., 1., 0., 1., 1.], device='cpu') \n",
      "\n",
      "0.8666666666666667\n",
      "threshold:  0.5294117 \n",
      "\n",
      "\n",
      "각 스킬별 정오답 시퀀스:  defaultdict(<class 'list'>, {83.0: [0.0], 100.0: [1.0, 1.0, 1.0], 82.0: [0.0, 0.0, 1.0], 20.0: [1.0]}) \n",
      "\n",
      "확률 변화값:  defaultdict(<class 'list'>, {83.0: [0.2943229675292969], 100.0: [0.39641210436820984, 0.5638629198074341, 0.6939181089401245], 82.0: [0.48700475692749023, 0.4790886640548706, 0.5294116735458374], 20.0: [0.7134891152381897]}) \n",
      "\n",
      "스킬별 last 확률값:  {83.0: 0.2943229675292969, 100.0: 0.6939181089401245, 82.0: 0.5294116735458374, 20.0: 0.7134891152381897} \n",
      "\n",
      "스킬별 평균 확률값:  {83.0: 0.2943229675292969, 100.0: 0.5513977110385895, 82.0: 0.4985016981760661, 20.0: 0.7134891152381897} \n",
      "\n",
      "{100: 'Translations', 82: 'Reflection', 83: 'Rotations', 20: 'Complementary and Supplementary Angles', 22: 'Congruence'}\n"
     ]
    }
   ],
   "source": [
    "idx = 9 #12 #25\n",
    "\n",
    "\n",
    "outputs = model(q[idx].long(), r[idx].long())\n",
    "outputs = (outputs * one_hot(qshft[idx].long(), model.num_q)).sum(-1) \n",
    "\n",
    "outputs = torch.masked_select(outputs, m[idx]).detach().cpu()\n",
    "t = torch.masked_select(rshft[idx], m[idx]).detach().cpu()\n",
    "\n",
    "\n",
    "idx_q = torch.masked_select(qshft[idx], m[idx]).detach().cpu()#.unique()\n",
    "idx_q = idx_q.tolist()\n",
    "\n",
    "\n",
    "student_q_seq = torch.masked_select(q[idx], m[idx]).detach().cpu().tolist()\n",
    "student_q_seq.append(idx_q[-1])\n",
    "print('학생의 문제 skill id 시퀀스: ', student_q_seq, '\\n')\n",
    "\n",
    "student_r_seq = torch.masked_select(r[idx], m[idx]).detach().cpu().tolist()\n",
    "student_r_seq.append(t.tolist()[-1])\n",
    "print('각 문제 정오답 여부 시퀀스: ', student_r_seq, '\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print('qshft 문제 시퀀스: ', idx_q, '\\n')\n",
    "\n",
    "print('output: ', outputs, '\\n')\n",
    "\n",
    "print('true: ', t, '\\n')\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    roc_auc_s = metrics.roc_auc_score(y_true=t.numpy(), y_score=outputs.numpy())\n",
    "    print(roc_auc_s)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true=t.numpy(), y_score=outputs.numpy())\n",
    "    optimal_idx = np.argmax(tpr-fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    print('threshold: ', optimal_threshold,'\\n\\n')\n",
    "\n",
    "except:\n",
    "#     roc_auc_s = \"all respond are same\"\n",
    "    print(\"all respond are same\")\n",
    "# print(roc_auc_s, '\\n')\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "r_dict = defaultdict(list)\n",
    "for idx, corr in enumerate(t.tolist()):\n",
    "    r_dict[idx_q[idx]].append(corr)\n",
    "print('각 스킬별 정오답 시퀀스: ',r_dict, '\\n')\n",
    "\n",
    "q_dict = defaultdict(list)\n",
    "for idx, p in enumerate(outputs.tolist()):\n",
    "    q_dict[idx_q[idx]].append(p)\n",
    "print('확률 변화값: ',q_dict, '\\n')\n",
    "\n",
    "q_last_dict = {}\n",
    "for k,v in q_dict.items():\n",
    "    q_last_dict[k] = v[-1]\n",
    "print('스킬별 last 확률값: ',q_last_dict, '\\n')\n",
    "\n",
    "q_mean_dict = {}\n",
    "for k,v in q_dict.items():\n",
    "    q_mean_dict[k] = np.mean(v)\n",
    "print('스킬별 평균 확률값: ',q_mean_dict, '\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lst = set(student_q_seq)\n",
    "skill_lst = {}\n",
    "for i in lst:\n",
    "    skill_lst[int(i)]=idx2q.get(int(i))\n",
    "print(skill_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 스킬별 마지막 정오답:  {83.0: 0.0, 100.0: 1.0, 82.0: 1.0, 20.0: 1.0} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "last_r_dict = dict()\n",
    "for idx, corr in enumerate(t.tolist()):\n",
    "    last_r_dict[idx_q[idx]]=corr\n",
    "print('각 스킬별 마지막 정오답: ',last_r_dict, '\\n')\n",
    "\n",
    "y_true = []\n",
    "for v in last_r_dict.values():\n",
    "    y_true.append(v)\n",
    "# y_true\n",
    "\n",
    "y_pred_last = []\n",
    "for v in q_last_dict.values():\n",
    "    y_pred_last.append(v)\n",
    "# y_pred_last\n",
    "\n",
    "y_pred_mean = []\n",
    "for v in q_mean_dict.values():\n",
    "    y_pred_mean.append(v)\n",
    "# y_pred_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last roc_auc_score:  1.0\n",
      "idx:  2 , threshold:  0.5294116735458374 \n",
      "\n",
      "\n",
      "mean roc_auc_score:  1.0\n",
      "idx:  2 , threshold:  0.4985016981760661\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    print(\"last roc_auc_score: \", metrics.roc_auc_score(y_true=np.array(y_true), y_score=np.array(y_pred_last)))\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true=np.array(y_true), y_score=np.array(y_pred_last))\n",
    "    optimal_idx = np.argmax(tpr-fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    print('idx: ', optimal_idx, ', threshold: ', optimal_threshold,'\\n\\n')\n",
    "    \n",
    "    print(\"mean roc_auc_score: \", metrics.roc_auc_score(y_true=np.array(y_true), y_score=np.array(y_pred_mean)))\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true=np.array(y_true), y_score=np.array(y_pred_mean))\n",
    "    optimal_idx = np.argmax(tpr-fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    print('idx: ', optimal_idx, ', threshold: ', optimal_threshold)\n",
    "\n",
    "\n",
    "#     roc = pd.DataFrame({\n",
    "#         'FPR(Fall-out)': fpr,\n",
    "#         'TPRate(Recall)': tpr,\n",
    "#         'Threshold': thresholds,\n",
    "#     })\n",
    "\n",
    "#     plt.scatter(fpr,tpr)\n",
    "#     plt.title('ROC curve')\n",
    "#     plt.xlabel('FPR')\n",
    "#     plt.ylabel('TPR')\n",
    "#     optimal_idx = np.argmax(tpr-fpr)\n",
    "#     optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "except:\n",
    "    if y_true[0] == 1: print('모두 맞을 듯')\n",
    "    else: print('모두 틀릴 듯')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실제 문제/정오답 시퀀스로부터 모델 Input 형태로 변환하기 위한 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_seq_len_small(q_seq, r_seq, seq_len, pad_val=-1):\n",
    "    proc_q_seqs = []\n",
    "    proc_r_seqs = []\n",
    "\n",
    "    i = 0\n",
    "    while i + seq_len + 1 < len(q_seq):\n",
    "        proc_q_seqs.append(q_seq[i:i + seq_len + 1])\n",
    "        proc_r_seqs.append(r_seq[i:i + seq_len + 1])\n",
    "\n",
    "        i += seq_len + 1\n",
    "\n",
    "    proc_q_seqs.append(\n",
    "        np.concatenate(\n",
    "            [\n",
    "                q_seq[i:],\n",
    "                np.array([pad_val] * (i + seq_len + 1 - len(q_seq)))\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    proc_r_seqs.append(\n",
    "        np.concatenate(\n",
    "            [\n",
    "                r_seq[i:],\n",
    "                np.array([pad_val] * (i + seq_len + 1 - len(q_seq)))\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return proc_q_seqs, proc_r_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    from torch.cuda import FloatTensor\n",
    "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "else:\n",
    "    from torch import FloatTensor\n",
    "\n",
    "def get_test_input(q_seq, r_seq, pad_val=-1, seq_len=10):\n",
    "    q_seq, r_seq = match_seq_len_small(q_seq, r_seq, seq_len)\n",
    "#     print(q_seq, r_seq)\n",
    "    \n",
    "    q_seqs = [FloatTensor(q_seq[0][:-1])]\n",
    "    r_seqs = [FloatTensor(r_seq[0][:-1])]\n",
    "    qshft_seqs = [FloatTensor(q_seq[0][1:])]\n",
    "    rshft_seqs = [FloatTensor(r_seq[0][1:])]\n",
    "    \n",
    "    q_seqs = pad_sequence(\n",
    "        q_seqs, batch_first=True, padding_value=pad_val\n",
    "    )\n",
    "    r_seqs = pad_sequence(\n",
    "        r_seqs, batch_first=True, padding_value=pad_val\n",
    "    )\n",
    "    qshft_seqs = pad_sequence(\n",
    "        qshft_seqs, batch_first=True, padding_value=pad_val\n",
    "    )\n",
    "    rshft_seqs = pad_sequence(\n",
    "        rshft_seqs, batch_first=True, padding_value=pad_val\n",
    "    )\n",
    "\n",
    "    mask_seqs = (q_seqs != pad_val) * (qshft_seqs != pad_val)\n",
    "\n",
    "    q_seqs, r_seqs, qshft_seqs, rshft_seqs = \\\n",
    "        q_seqs * mask_seqs, r_seqs * mask_seqs, qshft_seqs * mask_seqs, \\\n",
    "        rshft_seqs * mask_seqs\n",
    "\n",
    "    return q_seqs, r_seqs, qshft_seqs, rshft_seqs, mask_seqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "seq_len = 10\n",
    "q = np.array([1,2,3,4,5])\n",
    "r = np.array([1,1,0,0,0])\n",
    "\n",
    "data = get_test_input(q, r)\n",
    "q, r, qshft, rshft, m = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 0., -0., -0., -0., -0., -0.]]),\n",
       " tensor([[1., 1., 0., 0., 0., -0., -0., -0., -0., -0.]]),\n",
       " tensor([[2., 3., 4., 5., -0., -0., -0., -0., -0., -0.]]),\n",
       " tensor([[1., 0., 0., 0., -0., -0., -0., -0., -0., -0.]]),\n",
       " tensor([[ True,  True,  True,  True, False, False, False, False, False, False]]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data)\n",
    "# display(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model load 해서 inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DKT(\n",
       "  (interaction_emb): Embedding(220, 100)\n",
       "  (lstm_layer): LSTM(100, 100, batch_first=True)\n",
       "  (out_layer): Linear(in_features=100, out_features=110, bias=True)\n",
       "  (dropout_layer): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data_loaders.assist2009 import ASSIST2009\n",
    "\n",
    "dataset = ASSIST2009(100)\n",
    "\n",
    "import json\n",
    "\n",
    "with open(\"config.json\") as f:\n",
    "    config = json.load(f)\n",
    "    model_config = config[\"dkt\"]\n",
    "    train_config = config[\"train_config\"]\n",
    "    \n",
    "import torch \n",
    "from models.dkt import DKT\n",
    "\n",
    "model = DKT(dataset.num_q, **model_config)\n",
    "model.load_state_dict(torch.load('./ckpts/dkt/ASSIST2009/model.ckpt'))\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 100\n",
    "q = np.array([0,1,2,0,1,0,2,2,2,2,2,1,1,1])\n",
    "r = np.array([1,0,0,1,1,1,0,1,1,1,1,1,0,1])\n",
    "\n",
    "data = get_test_input(q, r, seq_len=seq_len)\n",
    "q, r, qshft, rshft, m = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import one_hot, binary_cross_entropy\n",
    "from sklearn import metrics\n",
    "\n",
    "outputs = model(q.long(), r.long()) #forward 호출 #embedding+LSTM\n",
    "outputs = (outputs * one_hot(qshft.long(), model.num_q)).sum(-1) #sum(-1): 열의 차원 제거, 행끼리 합 #[621,100]\n",
    "\n",
    "\n",
    "# masked_select(_, m): padding으로 맞춰줬던 애들 말고 실제 결과에 대해서만 가져오는거임!\n",
    "# .cpu(): gpu 메모리에 올려져있는 tensor를 cpu 메모리로 복사\n",
    "outputs = torch.masked_select(outputs, m).detach().cpu() #detach(): 연산 기록으로부터 분리하여 이후 연산 추적 방지\n",
    "                                                            #이 연산 기록으로부터 도함수가 계산되고 역전파가 이루어짐\n",
    "t = torch.masked_select(rshft, m).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_q = torch.masked_select(qshft, m).detach().cpu()#.unique()\n",
    "idx_q = idx_q.tolist()\n",
    "idx_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7970, 0.4924, 0.2355, 0.8247, 0.6862, 0.3728, 0.4605, 0.6377, 0.6361,\n",
       "        0.6394, 0.6455, 0.7802, 0.7380], device='cpu')"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs # 다음 번 문제 풀 때 모든 문제에 대해서 이 학생이 각 문제를 맞출 확률 (?) #110개 유형별"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.], device='cpu')"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "똑같은 99라도,\n",
    "유형은 같지만 똑같은 문제가 아님\n",
    "\n",
    "위치로 판별?\n",
    "\n",
    "LSTM - 시퀀스 순서가 중요\n",
    "+\n",
    "순서에 따라 확률이 달라질 수 있음\n",
    "\n",
    "**평균**? 맥스값?\n",
    "\n",
    "최종이라는 개념 없이, **조합**, 시퀀스가 중요\n",
    "\n",
    "한꺼번에 내뱉을 때, ex) 합격을 할/안할 확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 스킬별 정오답 시퀀스:  defaultdict(<class 'list'>, {1.0: [0.0, 1.0, 1.0, 0.0, 1.0], 2.0: [0.0, 0.0, 1.0, 1.0, 1.0, 1.0], 0.0: [1.0, 1.0]}) \n",
      "\n",
      "확률 변화값:  defaultdict(<class 'list'>, {1.0: [0.7969958782196045, 0.8247206211090088, 0.6455073356628418, 0.7801825404167175, 0.7379738092422485], 2.0: [0.49243322014808655, 0.3728359341621399, 0.46049731969833374, 0.6376556158065796, 0.6360715627670288, 0.6393502950668335], 0.0: [0.23547714948654175, 0.6862491965293884]}) \n",
      "\n",
      "스킬별 last 확률값:  {1.0: 0.7379738092422485, 2.0: 0.6393502950668335, 0.0: 0.6862491965293884} \n",
      "\n",
      "스킬별 평균 확률값:  {1.0: 0.7570760369300842, 2.0: 0.539807324608167, 0.0: 0.4608631730079651} \n",
      "\n",
      "각 스킬별 마지막 정오답:  {1.0: 1.0, 2.0: 1.0, 0.0: 1.0} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "r_dict = defaultdict(list)\n",
    "for idx, corr in enumerate(t.tolist()):\n",
    "    r_dict[idx_q[idx]].append(corr)\n",
    "print('각 스킬별 정오답 시퀀스: ',r_dict, '\\n')\n",
    "\n",
    "q_dict = defaultdict(list)\n",
    "for idx, p in enumerate(outputs.tolist()):\n",
    "    q_dict[idx_q[idx]].append(p)\n",
    "print('확률 변화값: ',q_dict, '\\n')\n",
    "\n",
    "q_last_dict = {}\n",
    "for k,v in q_dict.items():\n",
    "    q_last_dict[k] = v[-1]\n",
    "print('스킬별 last 확률값: ',q_last_dict, '\\n')\n",
    "\n",
    "q_mean_dict = {}\n",
    "for k,v in q_dict.items():\n",
    "    q_mean_dict[k] = np.mean(v)\n",
    "print('스킬별 평균 확률값: ',q_mean_dict, '\\n')\n",
    "\n",
    "last_r_dict = dict()\n",
    "for idx, corr in enumerate(t.tolist()):\n",
    "    last_r_dict[idx_q[idx]]=corr\n",
    "print('각 스킬별 마지막 정오답: ',last_r_dict, '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전체 테스트 데이터 가져와서 이것저것 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DKT(\n",
       "  (interaction_emb): Embedding(220, 100)\n",
       "  (lstm_layer): LSTM(100, 100, batch_first=True)\n",
       "  (out_layer): Linear(in_features=100, out_features=110, bias=True)\n",
       "  (dropout_layer): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data_loaders.assist2009 import ASSIST2009\n",
    "\n",
    "dataset = ASSIST2009(100)\n",
    "\n",
    "import json\n",
    "\n",
    "with open(\"config.json\") as f:\n",
    "    config = json.load(f)\n",
    "    model_config = config[\"dkt\"]\n",
    "    train_config = config[\"train_config\"]\n",
    "    \n",
    "import torch \n",
    "from models.dkt import DKT\n",
    "\n",
    "model = DKT(dataset.num_q, **model_config)\n",
    "model.load_state_dict(torch.load('./ckpts/dkt/ASSIST2009/model.ckpt'))\n",
    "\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "train_size = int(len(dataset) * 0.9)\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(\n",
    "        dataset, [train_size, test_size], generator=torch.Generator(device='cuda')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(dataset.dataset_dir, \"train_indices.pkl\")):\n",
    "    with open(\n",
    "        os.path.join(dataset.dataset_dir, \"train_indices.pkl\"), \"rb\"\n",
    "    ) as f:\n",
    "        train_dataset.indices = pickle.load(f)\n",
    "    with open(\n",
    "        os.path.join(dataset.dataset_dir, \"test_indices.pkl\"), \"rb\"\n",
    "    ) as f:\n",
    "        test_dataset.indices = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3033,\n",
       " 2472,\n",
       " 3162,\n",
       " 2923,\n",
       " 5573,\n",
       " 2811,\n",
       " 5855,\n",
       " 1246,\n",
       " 4762,\n",
       " 2742,\n",
       " 4477,\n",
       " 5916,\n",
       " 832,\n",
       " 2451,\n",
       " 426,\n",
       " 235,\n",
       " 4877,\n",
       " 4876,\n",
       " 2202,\n",
       " 4117,\n",
       " 3665,\n",
       " 2136,\n",
       " 6008,\n",
       " 2680,\n",
       " 2372,\n",
       " 906,\n",
       " 3528,\n",
       " 4107,\n",
       " 5005,\n",
       " 741,\n",
       " 4244,\n",
       " 3516,\n",
       " 4962,\n",
       " 5760,\n",
       " 3726,\n",
       " 5110,\n",
       " 1384,\n",
       " 4599,\n",
       " 5214,\n",
       " 2099,\n",
       " 4694,\n",
       " 2637,\n",
       " 5648,\n",
       " 3508,\n",
       " 3644,\n",
       " 5515,\n",
       " 576,\n",
       " 758,\n",
       " 3060,\n",
       " 4398,\n",
       " 1332,\n",
       " 5278,\n",
       " 3674,\n",
       " 5058,\n",
       " 5563,\n",
       " 4297,\n",
       " 2272,\n",
       " 1784,\n",
       " 1857,\n",
       " 4137,\n",
       " 5038,\n",
       " 4106,\n",
       " 2228,\n",
       " 3131,\n",
       " 1882,\n",
       " 5591,\n",
       " 4565,\n",
       " 5165,\n",
       " 6180,\n",
       " 492,\n",
       " 5413,\n",
       " 3908,\n",
       " 6097,\n",
       " 2112,\n",
       " 3303,\n",
       " 3217,\n",
       " 2198,\n",
       " 5928,\n",
       " 3489,\n",
       " 4970,\n",
       " 3209,\n",
       " 74,\n",
       " 18,\n",
       " 508,\n",
       " 4305,\n",
       " 5604,\n",
       " 4059,\n",
       " 4406,\n",
       " 2526,\n",
       " 5596,\n",
       " 5079,\n",
       " 4921,\n",
       " 932,\n",
       " 228,\n",
       " 524,\n",
       " 2955,\n",
       " 303,\n",
       " 244,\n",
       " 4826,\n",
       " 3024,\n",
       " 960,\n",
       " 1577,\n",
       " 5531,\n",
       " 1538,\n",
       " 2222,\n",
       " 1827,\n",
       " 407,\n",
       " 315,\n",
       " 5335,\n",
       " 2006,\n",
       " 5348,\n",
       " 5404,\n",
       " 4931,\n",
       " 3623,\n",
       " 2723,\n",
       " 3864,\n",
       " 2191,\n",
       " 2251,\n",
       " 6003,\n",
       " 617,\n",
       " 5190,\n",
       " 3677,\n",
       " 5284,\n",
       " 6142,\n",
       " 6111,\n",
       " 1274,\n",
       " 6200,\n",
       " 5016,\n",
       " 15,\n",
       " 2268,\n",
       " 1666,\n",
       " 3576,\n",
       " 5071,\n",
       " 5584,\n",
       " 3669,\n",
       " 4952,\n",
       " 1338,\n",
       " 1925,\n",
       " 3466,\n",
       " 3490,\n",
       " 375,\n",
       " 2011,\n",
       " 414,\n",
       " 3314,\n",
       " 2426,\n",
       " 4141,\n",
       " 3502,\n",
       " 2048,\n",
       " 3809,\n",
       " 5452,\n",
       " 2232,\n",
       " 218,\n",
       " 3911,\n",
       " 4390,\n",
       " 1280,\n",
       " 1286,\n",
       " 11,\n",
       " 5103,\n",
       " 776,\n",
       " 975,\n",
       " 712,\n",
       " 4280,\n",
       " 3890,\n",
       " 5756,\n",
       " 5671,\n",
       " 4064,\n",
       " 2513,\n",
       " 2057,\n",
       " 3574,\n",
       " 3586,\n",
       " 1379,\n",
       " 3061,\n",
       " 1363,\n",
       " 1206,\n",
       " 4012,\n",
       " 626,\n",
       " 313,\n",
       " 2383,\n",
       " 1793,\n",
       " 2692,\n",
       " 5318,\n",
       " 4807,\n",
       " 167,\n",
       " 2093,\n",
       " 1341,\n",
       " 3264,\n",
       " 858,\n",
       " 4307,\n",
       " 5936,\n",
       " 551,\n",
       " 4169,\n",
       " 6064,\n",
       " 3558,\n",
       " 3079,\n",
       " 1221,\n",
       " 6189,\n",
       " 2017,\n",
       " 2221,\n",
       " 4943,\n",
       " 3540,\n",
       " 68,\n",
       " 2022,\n",
       " 3659,\n",
       " 1320,\n",
       " 1269,\n",
       " 4026,\n",
       " 1179,\n",
       " 1458,\n",
       " 3007,\n",
       " 1195,\n",
       " 2543,\n",
       " 2810,\n",
       " 3834,\n",
       " 1120,\n",
       " 4318,\n",
       " 4912,\n",
       " 3875,\n",
       " 1625,\n",
       " 1314,\n",
       " 822,\n",
       " 5382,\n",
       " 1693,\n",
       " 420,\n",
       " 2129,\n",
       " 4801,\n",
       " 249,\n",
       " 5420,\n",
       " 4604,\n",
       " 5336,\n",
       " 653,\n",
       " 5151,\n",
       " 371,\n",
       " 2271,\n",
       " 517,\n",
       " 1639,\n",
       " 5159,\n",
       " 913,\n",
       " 1475,\n",
       " 1490,\n",
       " 1521,\n",
       " 2296,\n",
       " 5647,\n",
       " 2121,\n",
       " 522,\n",
       " 4881,\n",
       " 4122,\n",
       " 627,\n",
       " 2034,\n",
       " 2085,\n",
       " 5839,\n",
       " 2587,\n",
       " 2456,\n",
       " 4549,\n",
       " 5022,\n",
       " 743,\n",
       " 1698,\n",
       " 3711,\n",
       " 1757,\n",
       " 450,\n",
       " 1557,\n",
       " 4719,\n",
       " 1680,\n",
       " 6080,\n",
       " 2881,\n",
       " 4105,\n",
       " 1306,\n",
       " 1308,\n",
       " 81,\n",
       " 13,\n",
       " 4560,\n",
       " 545,\n",
       " 1550,\n",
       " 3656,\n",
       " 2663,\n",
       " 4432,\n",
       " 3406,\n",
       " 5880,\n",
       " 5039,\n",
       " 3953,\n",
       " 3128,\n",
       " 5628,\n",
       " 3981,\n",
       " 1674,\n",
       " 3722,\n",
       " 1183,\n",
       " 2898,\n",
       " 4749,\n",
       " 3051,\n",
       " 1415,\n",
       " 4316,\n",
       " 1008,\n",
       " 4170,\n",
       " 4445,\n",
       " 2571,\n",
       " 4134,\n",
       " 5846,\n",
       " 1083,\n",
       " 2790,\n",
       " 6116,\n",
       " 2696,\n",
       " 58,\n",
       " 4308,\n",
       " 905,\n",
       " 3138,\n",
       " 5874,\n",
       " 6184,\n",
       " 6199,\n",
       " 3613,\n",
       " 5750,\n",
       " 4420,\n",
       " 6196,\n",
       " 5455,\n",
       " 5090,\n",
       " 3145,\n",
       " 2632,\n",
       " 1941,\n",
       " 177,\n",
       " 2613,\n",
       " 4640,\n",
       " 1181,\n",
       " 3694,\n",
       " 1217,\n",
       " 2764,\n",
       " 5,\n",
       " 3291,\n",
       " 3219,\n",
       " 3907,\n",
       " 2343,\n",
       " 930,\n",
       " 3941,\n",
       " 4676,\n",
       " 3986,\n",
       " 446,\n",
       " 3836,\n",
       " 2330,\n",
       " 1486,\n",
       " 3393,\n",
       " 6071,\n",
       " 2362,\n",
       " 3032,\n",
       " 4221,\n",
       " 453,\n",
       " 6157,\n",
       " 3596,\n",
       " 4768,\n",
       " 2369,\n",
       " 4455,\n",
       " 5181,\n",
       " 2791,\n",
       " 111,\n",
       " 2996,\n",
       " 3278,\n",
       " 4485,\n",
       " 729,\n",
       " 2145,\n",
       " 4251,\n",
       " 5250,\n",
       " 2347,\n",
       " 2565,\n",
       " 2676,\n",
       " 942,\n",
       " 2806,\n",
       " 4155,\n",
       " 5104,\n",
       " 3755,\n",
       " 1578,\n",
       " 4857,\n",
       " 3850,\n",
       " 2245,\n",
       " 5169,\n",
       " 1408,\n",
       " 1393,\n",
       " 337,\n",
       " 5993,\n",
       " 3702,\n",
       " 3552,\n",
       " 3153,\n",
       " 3192,\n",
       " 4937,\n",
       " 4537,\n",
       " 2227,\n",
       " 35,\n",
       " 1016,\n",
       " 2275,\n",
       " 321,\n",
       " 3473,\n",
       " 865,\n",
       " 5833,\n",
       " 157,\n",
       " 1442,\n",
       " 4102,\n",
       " 1622,\n",
       " 2187,\n",
       " 4238,\n",
       " 3757,\n",
       " 299,\n",
       " 2620,\n",
       " 5615,\n",
       " 4729,\n",
       " 4110,\n",
       " 5036,\n",
       " 1092,\n",
       " 3972,\n",
       " 1861,\n",
       " 2018,\n",
       " 5826,\n",
       " 2579,\n",
       " 4149,\n",
       " 5097,\n",
       " 5654,\n",
       " 893,\n",
       " 5239,\n",
       " 3905,\n",
       " 2367,\n",
       " 4680,\n",
       " 389,\n",
       " 1210,\n",
       " 216,\n",
       " 965,\n",
       " 4113,\n",
       " 878,\n",
       " 3054,\n",
       " 5527,\n",
       " 4071,\n",
       " 3957,\n",
       " 2282,\n",
       " 5081,\n",
       " 5758,\n",
       " 2851,\n",
       " 4511,\n",
       " 3385,\n",
       " 4148,\n",
       " 737,\n",
       " 5101,\n",
       " 4736,\n",
       " 4841,\n",
       " 2442,\n",
       " 2086,\n",
       " 3995,\n",
       " 2772,\n",
       " 742,\n",
       " 155,\n",
       " 980,\n",
       " 3691,\n",
       " 5314,\n",
       " 5788,\n",
       " 702,\n",
       " 188,\n",
       " 2875,\n",
       " 948,\n",
       " 3964,\n",
       " 1015,\n",
       " 5801,\n",
       " 2512,\n",
       " 411,\n",
       " 1653,\n",
       " 5203,\n",
       " 2876,\n",
       " 300,\n",
       " 5360,\n",
       " 651,\n",
       " 5991,\n",
       " 1143,\n",
       " 1959,\n",
       " 1678,\n",
       " 3373,\n",
       " 1806,\n",
       " 3399,\n",
       " 5040,\n",
       " 3104,\n",
       " 3831,\n",
       " 861,\n",
       " 3019,\n",
       " 4851,\n",
       " 1837,\n",
       " 5276,\n",
       " 4662,\n",
       " 2808,\n",
       " 125,\n",
       " 5356,\n",
       " 4880,\n",
       " 2410,\n",
       " 3785,\n",
       " 5562,\n",
       " 3371,\n",
       " 366,\n",
       " 145,\n",
       " 6043,\n",
       " 4975,\n",
       " 2004,\n",
       " 2946,\n",
       " 5486,\n",
       " 2918,\n",
       " 459,\n",
       " 1772,\n",
       " 5629,\n",
       " 3155,\n",
       " 4735,\n",
       " 2724,\n",
       " 3737,\n",
       " 1474,\n",
       " 210,\n",
       " 345,\n",
       " 4312,\n",
       " 3547,\n",
       " 3787,\n",
       " 3915,\n",
       " 526,\n",
       " 4229,\n",
       " 5012,\n",
       " 5900,\n",
       " 4522,\n",
       " 1062,\n",
       " 1890,\n",
       " 1366,\n",
       " 2788,\n",
       " 5160,\n",
       " 1502,\n",
       " 1878,\n",
       " 5729,\n",
       " 5388,\n",
       " 4888,\n",
       " 1993,\n",
       " 1381,\n",
       " 5432,\n",
       " 5949,\n",
       " 5520,\n",
       " 4017,\n",
       " 1679,\n",
       " 3410,\n",
       " 3636,\n",
       " 4956,\n",
       " 511,\n",
       " 4060,\n",
       " 1735,\n",
       " 1364,\n",
       " 3065,\n",
       " 5056,\n",
       " 2643,\n",
       " 1128,\n",
       " 3357,\n",
       " 2862,\n",
       " 4780,\n",
       " 1064,\n",
       " 565,\n",
       " 1207,\n",
       " 1561,\n",
       " 5244,\n",
       " 4412,\n",
       " 2181,\n",
       " 815,\n",
       " 3917,\n",
       " 384,\n",
       " 4301,\n",
       " 1888,\n",
       " 5670,\n",
       " 5428,\n",
       " 4588,\n",
       " 3088,\n",
       " 3329,\n",
       " 2490,\n",
       " 1460,\n",
       " 3707,\n",
       " 2329,\n",
       " 5995,\n",
       " 4286,\n",
       " 1508,\n",
       " 1778,\n",
       " 1000,\n",
       " 3454,\n",
       " 1038,\n",
       " 3341,\n",
       " 2139,\n",
       " 1148,\n",
       " 1770,\n",
       " 5893,\n",
       " 325,\n",
       " 5065,\n",
       " 6108,\n",
       " 4074,\n",
       " 5042,\n",
       " 3407,\n",
       " 2866,\n",
       " 5319,\n",
       " 5944,\n",
       " 3861,\n",
       " 1702,\n",
       " 1727,\n",
       " 5170,\n",
       " 3122,\n",
       " 5676,\n",
       " 2318,\n",
       " 1069,\n",
       " 3366,\n",
       " 2464,\n",
       " 903,\n",
       " 1997,\n",
       " 1599,\n",
       " 5168,\n",
       " 3913,\n",
       " 2060,\n",
       " 1715,\n",
       " 2645,\n",
       " 645,\n",
       " 1777,\n",
       " 2204,\n",
       " 5990,\n",
       " 2150,\n",
       " 1939,\n",
       " 3330,\n",
       " 581,\n",
       " 2522,\n",
       " 95,\n",
       " 2384,\n",
       " 4247,\n",
       " 3244,\n",
       " 646,\n",
       " 5918,\n",
       " 4918,\n",
       " 4309,\n",
       " 1032]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스킬별 last 확률값:  {1.0: 0.7379738092422485, 2.0: 0.6393502950668335, 0.0: 0.6862491965293884} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "q_last_dict = {}\n",
    "for k,v in q_dict.items():\n",
    "    q_last_dict[k] = v[-1]\n",
    "print('스킬별 last 확률값: ',q_last_dict, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스킬별 확률 변화값:  defaultdict(<class 'list'>, {1.0: [0.7969958782196045, 0.8247206211090088, 0.6455073356628418, 0.7801825404167175, 0.7379738092422485], 2.0: [0.49243322014808655, 0.3728359341621399, 0.46049731969833374, 0.6376556158065796, 0.6360715627670288, 0.6393502950668335], 0.0: [0.23547714948654175, 0.6862491965293884]}) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "q_dict = defaultdict(list)\n",
    "for idx, p in enumerate(outputs.tolist()):\n",
    "    q_dict[idx_q[idx]].append(p)\n",
    "print('스킬별 확률 변화값: ',q_dict, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0, 1.0, 2.0}"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_q = set(idx_q)\n",
    "unique_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.utils import collate_fn\n",
    "\n",
    "# train_loader = DataLoader(\n",
    "#         train_dataset, batch_size=256, shuffle=True,\n",
    "#         collate_fn=collate_fn, generator=torch.Generator(device='cuda') #0607 hson\n",
    "#     )\n",
    "test_loader = DataLoader(\n",
    "        test_dataset, batch_size=test_size, shuffle=False,\n",
    "        collate_fn=collate_fn, generator=torch.Generator(device='cuda') #0607 hson\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스킬별 last 확률값:  {1.0: 0.7570760369300842, 2.0: 0.539807324608167, 0.0: 0.4608631730079651} \n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in test_loader:\n",
    "    q, r, qshft, rshft, m = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  1.,   1.,   1.,  ...,  52.,   2.,   2.],\n",
       "         [ 49.,  67.,  18.,  ...,  -0.,  -0.,  -0.],\n",
       "         [ 58.,  58.,  59.,  ...,  -0.,  -0.,  -0.],\n",
       "         ...,\n",
       "         [  3.,   3.,   3.,  ...,  -0.,  -0.,  -0.],\n",
       "         [ 67., 102., 102.,  ...,  -0.,  -0.,  -0.],\n",
       "         [ 23.,  23.,  23.,  ..., 102., 102., 102.]]),\n",
       " tensor([[1., 0., 1.,  ..., 1., 0., 1.],\n",
       "         [0., 0., 0.,  ..., -0., -0., -0.],\n",
       "         [0., 0., 1.,  ..., -0., -0., -0.],\n",
       "         ...,\n",
       "         [0., 1., 1.,  ..., -0., -0., -0.],\n",
       "         [0., 0., 1.,  ..., -0., -0., -0.],\n",
       "         [0., 1., 1.,  ..., 0., 0., 1.]]),\n",
       " tensor([[  1.,   1.,   1.,  ...,   2.,   2.,   2.],\n",
       "         [ 67.,  18.,  35.,  ...,  -0.,  -0.,  -0.],\n",
       "         [ 58.,  59.,  58.,  ...,  -0.,  -0.,  -0.],\n",
       "         ...,\n",
       "         [  3.,   3.,   3.,  ...,  -0.,  -0.,  -0.],\n",
       "         [102., 102., 102.,  ...,  -0.,  -0.,  -0.],\n",
       "         [ 23.,  23.,  23.,  ..., 102., 102.,  35.]]),\n",
       " tensor([[0., 1., 1.,  ..., 0., 1., 1.],\n",
       "         [0., 0., 0.,  ..., -0., -0., -0.],\n",
       "         [0., 1., 0.,  ..., -0., -0., -0.],\n",
       "         ...,\n",
       "         [1., 1., 0.,  ..., -0., -0., -0.],\n",
       "         [0., 1., 1.,  ..., -0., -0., -0.],\n",
       "         [1., 1., 1.,  ..., 0., 1., 0.]]),\n",
       " tensor([[ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [ True,  True,  True,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ..., False, False, False],\n",
       "         ...,\n",
       "         [ True,  True,  True,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ...,  True,  True,  True]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 22.,  83., 100.,  82., 100., 100.,  82.,  82.,   0.,  -0.,  -0.,  -0.,\n",
       "         -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,\n",
       "         -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,\n",
       "         -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,\n",
       "         -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,\n",
       "         -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,\n",
       "         -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,\n",
       "         -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,  -0.,\n",
       "         -0.,  -0.,  -0.,  -0.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qshft[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rshft[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import one_hot, binary_cross_entropy\n",
    "from sklearn import metrics\n",
    "\n",
    "outputs = model(q[idx].long(), r[idx].long()) #forward 호출 #embedding+LSTM\n",
    "outputs = (outputs * one_hot(qshft[idx].long(), model.num_q)).sum(-1) #sum(-1): 열의 차원 제거, 행끼리 합 #[621,100]\n",
    "\n",
    "\n",
    "# masked_select(_, m): padding으로 맞춰줬던 애들 말고 실제 결과에 대해서만 가져오는거임!\n",
    "# .cpu(): gpu 메모리에 올려져있는 tensor를 cpu 메모리로 복사\n",
    "outputs = torch.masked_select(outputs, m[idx]).detach().cpu() #detach(): 연산 기록으로부터 분리하여 이후 연산 추적 방지\n",
    "                                                            #이 연산 기록으로부터 도함수가 계산되고 역전파가 이루어짐\n",
    "t = torch.masked_select(rshft[idx], m[idx]).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83.0, 100.0, 82.0, 100.0, 100.0, 82.0, 82.0, 20.0]\n"
     ]
    }
   ],
   "source": [
    "idx_q = torch.masked_select(qshft[idx], m[idx]).detach().cpu()#.unique()\n",
    "idx_q = idx_q.tolist()\n",
    "print(idx_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2943, 0.3964, 0.4870, 0.5639, 0.6939, 0.4791, 0.5294, 0.7135],\n",
       "       device='cpu')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs # 다음 번 문제 풀 때 모든 문제에 대해서 이 학생이 각 문제를 맞출 확률 (?) #110개 유형별"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0., 1., 1., 0., 1., 1.], device='cpu')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    roc_auc_s = metrics.roc_auc_score(y_true=t.numpy(), y_score=outputs.numpy())\n",
    "#     print(roc_auc_s)\n",
    "except:\n",
    "    roc_auc_s = \"all respond are same\"\n",
    "#     print(\"all respond are same\")\n",
    "print(roc_auc_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{82.0, 83.0, 100.0, 20.0}\n"
     ]
    }
   ],
   "source": [
    "unique_q = set(idx_q)\n",
    "print(unique_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {83.0: [0.0],\n",
       "             100.0: [1.0, 1.0, 1.0],\n",
       "             82.0: [0.0, 0.0, 1.0],\n",
       "             20.0: [1.0]})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "r_dict = defaultdict(list)\n",
    "for idx, corr in enumerate(t.tolist()):\n",
    "    r_dict[idx_q[idx]].append(corr)\n",
    "r_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {83.0: [0.2943229675292969],\n",
       "             100.0: [0.39641210436820984,\n",
       "              0.5638629198074341,\n",
       "              0.6939181089401245],\n",
       "             82.0: [0.48700475692749023,\n",
       "              0.4790886640548706,\n",
       "              0.5294116735458374],\n",
       "             20.0: [0.7134891152381897]})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_dict = defaultdict(list)\n",
    "for i, p in enumerate(outputs.tolist()):\n",
    "    q_dict[idx_q[i]].append(p)\n",
    "q_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{83.0: 0.2943229675292969,\n",
       " 100.0: 0.6939181089401245,\n",
       " 82.0: 0.5294116735458374,\n",
       " 20.0: 0.7134891152381897}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_last_dict = {}\n",
    "for k,v in q_dict.items():\n",
    "    q_last_dict[k] = v[-1]\n",
    "q_last_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{83.0: 0.2943229675292969,\n",
       " 100.0: 0.5513977110385895,\n",
       " 82.0: 0.4985016981760661,\n",
       " 20.0: 0.7134891152381897}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_mean_dict = {}\n",
    "for k,v in q_dict.items():\n",
    "    q_mean_dict[k] = np.mean(v)\n",
    "q_mean_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"datasets/ASSIST2009/\"\n",
    "with open(os.path.join(DATASET_DIR, \"q2idx.pkl\"), \"rb\") as f:\n",
    "    q2idx = pickle.load(f)\n",
    "idx2q = {v:k for k,v in q2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Absolute Value',\n",
       " 1: 'Addition Whole Numbers',\n",
       " 2: 'Addition and Subtraction Fractions',\n",
       " 3: 'Addition and Subtraction Integers',\n",
       " 4: 'Addition and Subtraction Positive Decimals',\n",
       " 5: 'Algebraic Simplification',\n",
       " 6: 'Algebraic Solving',\n",
       " 7: 'Angles - Obtuse, Acute, and Right',\n",
       " 8: 'Angles on Parallel Lines Cut by a Transversal',\n",
       " 9: 'Area Circle',\n",
       " 10: 'Area Irregular Figure',\n",
       " 11: 'Area Parallelogram',\n",
       " 12: 'Area Rectangle',\n",
       " 13: 'Area Trapezoid',\n",
       " 14: 'Area Triangle',\n",
       " 15: 'Box and Whisker',\n",
       " 16: 'Calculations with Similar Figures',\n",
       " 17: 'Choose an Equation from Given Information',\n",
       " 18: 'Circle Graph',\n",
       " 19: 'Circumference ',\n",
       " 20: 'Complementary and Supplementary Angles',\n",
       " 21: 'Computation with Real Numbers',\n",
       " 22: 'Congruence',\n",
       " 23: 'Conversion of Fraction Decimals Percents',\n",
       " 24: 'Counting Methods',\n",
       " 25: 'D.4.8-understanding-concept-of-probabilities',\n",
       " 26: 'Distributive Property',\n",
       " 27: 'Divisibility Rules',\n",
       " 28: 'Division Fractions',\n",
       " 29: 'Effect of Changing Dimensions of a Shape Prportionally',\n",
       " 30: 'Equation Solving More Than Two Steps',\n",
       " 31: 'Equation Solving Two or Fewer Steps',\n",
       " 32: 'Equivalent Fractions',\n",
       " 33: 'Estimation',\n",
       " 34: 'Exponents',\n",
       " 35: 'Finding Percents',\n",
       " 36: 'Finding Slope From Equation',\n",
       " 37: 'Finding Slope From Situation',\n",
       " 38: 'Finding Slope from Ordered Pairs',\n",
       " 39: 'Fraction Of',\n",
       " 40: 'Greatest Common Factor',\n",
       " 41: 'Histogram as Table or Graph',\n",
       " 42: 'Intercept',\n",
       " 43: 'Interior Angles Figures with More than 3 Sides',\n",
       " 44: 'Interior Angles Triangle',\n",
       " 45: 'Interpreting Coordinate Graphs ',\n",
       " 46: 'Least Common Multiple',\n",
       " 47: 'Linear Equations',\n",
       " 48: 'Mean',\n",
       " 49: 'Median',\n",
       " 50: 'Midpoint',\n",
       " 51: 'Mode',\n",
       " 52: 'Multiplication Fractions',\n",
       " 53: 'Multiplication Whole Numbers',\n",
       " 54: 'Multiplication and Division Integers',\n",
       " 55: 'Multiplication and Division Positive Decimals',\n",
       " 56: 'Nets of 3D Figures',\n",
       " 57: 'Number Line',\n",
       " 58: 'Order of Operations +,-,/,* () positive reals',\n",
       " 59: 'Order of Operations All',\n",
       " 60: 'Ordering Fractions',\n",
       " 61: 'Ordering Integers',\n",
       " 62: 'Ordering Positive Decimals',\n",
       " 63: 'Ordering Real Numbers',\n",
       " 64: 'Parts of a Polyomial, Terms, Coefficient, Monomial, Exponent, Variable',\n",
       " 65: 'Pattern Finding ',\n",
       " 66: 'Percent Discount',\n",
       " 67: 'Percent Of',\n",
       " 68: 'Percents',\n",
       " 69: 'Perimeter of a Polygon',\n",
       " 70: 'Polynomial Factors',\n",
       " 71: 'Prime Number',\n",
       " 72: 'Probability of Two Distinct Events',\n",
       " 73: 'Probability of a Single Event',\n",
       " 74: 'Proportion',\n",
       " 75: 'Pythagorean Theorem',\n",
       " 76: 'Quadratic Formula to Solve Quadratic Equation',\n",
       " 77: 'Range',\n",
       " 78: 'Rate',\n",
       " 79: 'Reading a Ruler or Scale',\n",
       " 80: 'Recognize Linear Pattern',\n",
       " 81: 'Recognize Quadratic Pattern',\n",
       " 82: 'Reflection',\n",
       " 83: 'Rotations',\n",
       " 84: 'Rounding',\n",
       " 85: 'Scale Factor',\n",
       " 86: 'Scatter Plot',\n",
       " 87: 'Scientific Notation',\n",
       " 88: 'Simplifying Expressions positive exponents',\n",
       " 89: 'Slope',\n",
       " 90: 'Solving Inequalities',\n",
       " 91: 'Solving Systems of Linear Equations',\n",
       " 92: 'Solving Systems of Linear Equations by Graphing',\n",
       " 93: 'Solving for a variable',\n",
       " 94: 'Square Root',\n",
       " 95: 'Stem and Leaf Plot',\n",
       " 96: 'Subtraction Whole Numbers',\n",
       " 97: 'Surface Area Cylinder',\n",
       " 98: 'Surface Area Rectangular Prism',\n",
       " 99: 'Table',\n",
       " 100: 'Translations',\n",
       " 101: 'Unit Conversion Within a System',\n",
       " 102: 'Unit Rate',\n",
       " 103: 'Venn Diagram',\n",
       " 104: 'Volume Cylinder',\n",
       " 105: 'Volume Rectangular Prism',\n",
       " 106: 'Volume Sphere',\n",
       " 107: 'Write Linear Equation from Graph',\n",
       " 108: 'Write Linear Equation from Ordered Pairs',\n",
       " 109: 'Write Linear Equation from Situation'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0., 58., 99.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[120].unique()\n",
    "# q[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학생의 문제 skill id 시퀀스:  [22.0, 83.0, 100.0, 82.0, 100.0, 100.0, 82.0, 82.0, 20.0] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "student_q_seq = torch.masked_select(q[idx], m[idx]).detach().cpu().tolist()\n",
    "student_q_seq.append(idx_q[-1])\n",
    "print('학생의 문제 skill id 시퀀스: ', student_q_seq, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{100: 'Translations',\n",
       " 82: 'Reflection',\n",
       " 83: 'Rotations',\n",
       " 20: 'Complementary and Supplementary Angles',\n",
       " 22: 'Congruence'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(idx2q.get(48))\n",
    "# print(idx2q.get(49))\n",
    "# print(idx2q.get(103))\n",
    "\n",
    "lst = set(student_q_seq)\n",
    "skill_lst = {}\n",
    "for i in lst:\n",
    "    skill_lst[int(i)]=idx2q.get(int(i))\n",
    "#     print(int(i), idx2q.get(int(i)))\n",
    "skill_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "절댓값, 정수는 중1-1\n",
    "평균,중앙값,최빈값은 중3-2\n",
    "줄기와 잎그림은 중1-2\n",
    "\n",
    "- 참고\n",
    "    https://m.blog.naver.com/guitarpsy/60205245942"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import one_hot, binary_cross_entropy\n",
    "from sklearn import metrics\n",
    "\n",
    "DATASET_DIR = \"datasets/ASSIST2009/\"\n",
    "with open(os.path.join(DATASET_DIR, \"q2idx.pkl\"), \"rb\") as f:\n",
    "    q2idx = pickle.load(f)\n",
    "idx2q = {v:k for k,v in q2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_path = \"./sample_under_30_simple.json\"\n",
    "\n",
    "data = {}\n",
    "\n",
    "\n",
    "data['student'] = []\n",
    "for i in range(len(q)):\n",
    "    idx = i\n",
    "\n",
    "    outputs = model(q[idx].long(), r[idx].long())\n",
    "    outputs = (outputs * one_hot(qshft[idx].long(), model.num_q)).sum(-1) \n",
    "\n",
    "    outputs = torch.masked_select(outputs, m[idx]).detach().cpu().numpy()\n",
    "    t = torch.masked_select(rshft[idx], m[idx]).detach().cpu().numpy()\n",
    "\n",
    "    if len(t) == 0 or len(t) > 30: continue\n",
    "#     if len(t) == 0: continue\n",
    "    \n",
    "    \n",
    "    idx_q = torch.masked_select(qshft[idx], m[idx]).detach().cpu()#.unique()\n",
    "    idx_q = idx_q.tolist()\n",
    "    # print('qshft 문제 시퀀스: ', idx_q, '\\n')\n",
    "    \n",
    "    try:\n",
    "        roc_auc_s = metrics.roc_auc_score(y_true=t, y_score=outputs) #json numpy 저장 때문에 output,t type 을 바꿔서 여기도 조정\n",
    "    except:\n",
    "        roc_auc_s = \"all respond are same\"\n",
    "#     print(roc_auc_s)\n",
    "    \n",
    "    \n",
    "    student_q_seq = torch.masked_select(q[idx], m[idx]).detach().cpu().tolist()\n",
    "    student_q_seq.append(idx_q[-1])\n",
    "#     print('학생의 문제 skill id 시퀀스: ', student_q_seq, '\\n')\n",
    "\n",
    "    student_r_seq = torch.masked_select(r[idx], m[idx]).detach().cpu().tolist()\n",
    "    student_r_seq.append(t.tolist()[-1])\n",
    "#     print('각 문제 정오답 여부 시퀀스: ', student_r_seq, '\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     print('output: ', outputs, '\\n')\n",
    "\n",
    "#     print('true: ', t, '\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    r_dict = defaultdict(list)\n",
    "    for i, corr in enumerate(t.tolist()):\n",
    "        r_dict[idx_q[i]].append(corr)\n",
    "#     print('각 스킬별 정오답 시퀀스: ',r_dict, '\\n')\n",
    "\n",
    "    q_dict = defaultdict(list)\n",
    "    for j, p in enumerate(outputs.tolist()):\n",
    "        q_dict[idx_q[j]].append(p)\n",
    "#     print('확률 변화값: ',q_dict, '\\n')\n",
    "\n",
    "    q_last_dict = {}\n",
    "    for k,v in q_dict.items():\n",
    "        q_last_dict[k] = v[-1]\n",
    "#     print('스킬별 last 확률값: ',q_last_dict, '\\n')\n",
    "\n",
    "    q_mean_dict = {}\n",
    "    for k,v in q_dict.items():\n",
    "        q_mean_dict[k] = np.mean(v)\n",
    "#     print('스킬별 평균 확률값: ',q_mean_dict, '\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    lst = set(student_q_seq)\n",
    "    skill_lst = {}\n",
    "    for i in lst:\n",
    "        skill_lst[int(i)]=idx2q.get(int(i))\n",
    "#     print(skill_lst)\n",
    "\n",
    "\n",
    "\n",
    "    data['student'].append({\n",
    "        'student_id': idx,\n",
    "#         '학생의 문제 skill id 시퀀스:': student_q_seq,\n",
    "#         '학생의 문제 정오답 여부 시퀀스': student_r_seq,\n",
    "#         'outputs': outputs,\n",
    "#         'true': t,\n",
    "        '문제 unique skill id': list(r_dict.keys()),\n",
    "        'roc auc score': roc_auc_s,\n",
    "        '각 스킬별 정오답 시퀀스': r_dict,\n",
    "        '다음 Step 확률 변화값': q_dict,\n",
    "        '스킬별 last 확률값': q_last_dict,\n",
    "        '스킬별 평균 확률값': q_mean_dict,\n",
    "        '각 스킬 단원명': skill_lst,   \n",
    "    })\n",
    "\n",
    "    \n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "    \n",
    "with open(file_path, 'w') as outfile:\n",
    "    json.dump(data, outfile, indent=None, cls=NumpyEncoder, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
